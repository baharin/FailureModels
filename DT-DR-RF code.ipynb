{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "RULEFIT:"
      ],
      "metadata": {
        "id": "KrGS9BWLUxsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/christophM/rulefit.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M8h8Vfi774t",
        "outputId": "ea2dc4a5-0a9b-4aed-e119-9f5913beb360"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/christophM/rulefit.git\n",
            "  Cloning https://github.com/christophM/rulefit.git to /tmp/pip-req-build-dhoxgd99\n",
            "  Running command git clone -q https://github.com/christophM/rulefit.git /tmp/pip-req-build-dhoxgd99\n",
            "Requirement already satisfied: scikit-learn>=0.20.2 in /usr/local/lib/python3.8/dist-packages (from RuleFit==0.3) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.16.1 in /usr/local/lib/python3.8/dist-packages (from RuleFit==0.3) (1.21.6)\n",
            "Requirement already satisfied: pandas>=0.24.1 in /usr/local/lib/python3.8/dist-packages (from RuleFit==0.3) (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.1->RuleFit==0.3) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.24.1->RuleFit==0.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=0.24.1->RuleFit==0.3) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.2->RuleFit==0.3) (1.2.0)\n",
            "Building wheels for collected packages: RuleFit\n",
            "  Building wheel for RuleFit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for RuleFit: filename=RuleFit-0.3-py3-none-any.whl size=8797 sha256=898a4a60235a6515bfaf02c2026d4133cf14581e31d10611aa900e603a30ac0c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-cxzmwfzz/wheels/8d/f1/8a/80d74a55f8d14e55f3f1ff050b6f9292abbb0d6de12100e410\n",
            "Successfully built RuleFit\n",
            "Installing collected packages: RuleFit\n",
            "Successfully installed RuleFit-0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
        "import pandas as pd \n",
        "import math\n",
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLBiGE50Z-6s",
        "outputId": "cdc29bec-d754-44f4-b01c-8e7cc928c65b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 2.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QggJTwK66w0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from rulefit import RuleFit\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
        "import time\n",
        "\n",
        "\n",
        "pd.set_option('display.max_rows', None)\n",
        "# autopilot_r1_data = pd.read_csv(\"/content/autopilot_R1_6_regression_3500_value_1.csv\")\n",
        "\n",
        "# y = autopilot_r1_data.Label.values\n",
        "# X = autopilot_r1_data.drop(\"Label\", axis=1)\n",
        "\n",
        "# features = X.columns\n",
        "# X = X.values\n",
        "\n",
        "# rf = RuleFit()\n",
        "# rf.fit(X, y, feature_names=features)\n",
        "# y_pred = rf.predict(X)\n",
        "\n",
        "\n",
        "# rules = rf.get_rules()\n",
        "\n",
        "# rules = rules[rules.coef != 0].sort_values(by=\"support\")\n",
        "# num_rules_rule = len(rules[rules.type == 'rule'])\n",
        "# num_rules_linear = len(rules[rules.type == 'linear'])\n",
        "# print(rules.sort_values('importance', ascending=False))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingRegressor,GradientBoostingClassifier, RandomForestClassifier, RandomForestRegressor\n",
        "from rulefit import RuleFit\n",
        "\n",
        "\n",
        "boston_data = pd.read_csv(\"/content/tustin_R1e_regression_3500_value_1.csv\")\n",
        "\n",
        "y = boston_data.Label.values\n",
        "X = boston_data.drop(\"Label\", axis=1)\n",
        "print(y)\n",
        "features = X.columns\n",
        "X = X.values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "typ = 'classifier' #regressor or classifier\n",
        "\n",
        "if typ == 'regressor':\n",
        "    rf = RuleFit(\n",
        "        rfmode='regress',\n",
        "        tree_generator=RandomForestRegressor()\n",
        "    )\n",
        "    rf.fit(X, y, feature_names=features)\n",
        "    y_pred = rf.predict(X)\n",
        "    insample_rmse = np.sqrt(np.sum((y_pred - y)**2)/len(y))\n",
        "    print(insample_rmse)\n",
        "elif typ == 'classifier':\n",
        "    y_class = y.copy()\n",
        "    N = X.shape[0]\n",
        "    time_stamp1 = time.time()\n",
        "    rf = RuleFit(   rfmode='classify',\n",
        "                    tree_generator=RandomForestClassifier()\n",
        "                )\n",
        "    rf.fit(X_train, y_train, feature_names=features)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    # y_proba = rf.predict_proba(X)\n",
        "    # insample_acc = sum(y_pred == y_train) / len(y_train)\n",
        "    time_stamp2 = time.time()\n",
        "    elapsed_time = time_stamp2 - time_stamp1\n",
        "    # print(insample_acc)\n",
        "\n",
        "rules = rf.get_rules()\n",
        "\n",
        "rules = rules[rules.coef == 0].sort_values(by=\"support\")\n",
        "num_rules_rule = len(rules[rules.type == 'rule'])\n",
        "num_rules_linear = len(rules[rules.type == 'linear'])\n",
        "# print(rules.sort_values('importance', ascending=False))"
      ],
      "metadata": {
        "id": "uvN7OCUpY0DK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rules = rf.get_rules()\n",
        "# # rules = rules[rules.coef != 0].sort_values(by=\"support\")\n",
        "# rules = rules[rules.coef == 0].sort_values(\"support\", ascending=False)\n",
        "\n",
        "# print(rules)"
      ],
      "metadata": {
        "id": "GrRWdgodEcTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "accuracy = accuracy_score(y_pred,y_test)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_pred, y_test).ravel()\n",
        "\n",
        "precisionpass = (tp) / (tp + fp)\n",
        "recallpass = (tp) / (tp + fn)\n",
        "\n",
        "precisionfail = (tn) / (tn + fn)\n",
        "recallfail = (tn) / (tn + fp)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"balanced accuracy: \", balanced_accuracy_score(y_pred,y_test))\n",
        "print(\"recall pass: \", recallpass)\n",
        "print(\"recall fail: \", recallfail)\n",
        "print(\"precision pass: \", precisionpass)\n",
        "\n",
        "print(\"precision fail: \", precisionfail)\n",
        "print(\"elapsed time\", elapsed_time)"
      ],
      "metadata": {
        "id": "Ts0LlNo1INd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OKuPaChoTZUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz3mv4ZGtaQQ",
        "outputId": "a54f287a-1305-4ccb-b529-23f2934d12bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[K     |████████████████████████████████| 100 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.8/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DECISION TREE\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, balanced_accuracy_score\n",
        "import pandas as pd \n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer\n",
        "import math\n",
        "\n",
        "data = pd.read_csv(\"tustinr4_R4b_regression_3500_value_1.csv\")\n",
        "\n",
        "#y = data.Label.values\n",
        "#X = data.drop(\"Label\", axis = 1)\n",
        "#X = X.drop(\"Fitness\", axis = 1)\n",
        "\n",
        "testdata = pd.read_csv(\"tustinr4_R4b_regression_3500_value_2.csv\")\n",
        "\n",
        "\n",
        "\n",
        "X_train = data.drop(\"Label\", axis = 1)\n",
        "X_train = X_train.drop(\"Fitness\", axis = 1)\n",
        "y_train = data.Label.values\n",
        "\n",
        "X_test = testdata.drop(\"Label\", axis = 1)\n",
        "X_test = X_test.drop(\"Fitness\", axis = 1)\n",
        "y_test = testdata.Label.values\n",
        "\n",
        "dtmodel = BayesSearchCV(tree.DecisionTreeClassifier(random_state = 0), {'min_samples_leaf': Integer(1, max(2, math.floor(len(y_train/2))))}, n_iter = 100, optimizer_kwargs = {'acq_func': 'EI'})\n",
        "\n",
        "dtmodel.fit(X_train[:300], y_train[:300])\n",
        "\n",
        "clf = dtmodel.best_estimator_\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "precisionpass = (tp) / (tp + fp)\n",
        "recallpass = (tp) / (tp + fn)\n",
        "\n",
        "precisionfail = (tn) / (tn + fn)\n",
        "recallfail = (tn) / (tn + fp)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"balanced accuracy: \", balanced_accuracy_score(y_test, y_pred))\n",
        "print(\"recall pass: \", recallpass)\n",
        "print(\"recall fail: \", recallfail)\n",
        "print(\"precision pass: \", precisionpass)\n",
        "\n",
        "print(\"precision fail: \", precisionfail)\n",
        "\n",
        "print(y_pred.tolist())"
      ],
      "metadata": {
        "id": "toEjPAwcUvca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f814231d-e999-4ae9-8e87-871247b184e6"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98        52\n",
            "           1       1.00      0.96      0.98        48\n",
            "\n",
            "    accuracy                           0.98       100\n",
            "   macro avg       0.98      0.98      0.98       100\n",
            "weighted avg       0.98      0.98      0.98       100\n",
            "\n",
            "accuracy:  0.98\n",
            "balanced accuracy:  0.9791666666666667\n",
            "recall pass:  0.9583333333333334\n",
            "recall fail:  1.0\n",
            "precision pass:  1.0\n",
            "precision fail:  0.9629629629629629\n",
            "[0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "aVD6Fvf1_5jB",
        "outputId": "60870b45-8724-4765-aaee-23ff0f771639"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Type  TrainDelta  TestDelta  AP_Eng1  AP_Eng2  AP_Eng3  HDG_Mode1  \\\n",
              "0       0           0          0        1        0        0          1   \n",
              "1       0           0          0        0        1        0          1   \n",
              "2       0           0          0        0        1        0          0   \n",
              "3       0           0          0        1        1        1          0   \n",
              "4       0           0          0        1        0        1          0   \n",
              "..    ...         ...        ...      ...      ...      ...        ...   \n",
              "596     0           0          0        1        0        0          1   \n",
              "597     0           0          0        1        0        0          0   \n",
              "598     0           0          0        0        0        0          0   \n",
              "599     0           0          0        1        0        1          0   \n",
              "600     0           0          0        1        0        0          1   \n",
              "\n",
              "     HDG_Mode2  HDG_Mode3  ALT_Mode1  ...    HDG_Ref3     TurnK1     TurnK2  \\\n",
              "0            1          0          1  ...  -89.042279  32.909379  43.025749   \n",
              "1            0          1          0  ...  -93.109998  19.364039  38.210679   \n",
              "2            1          1          0  ... -113.480226   2.899508  25.331430   \n",
              "3            1          1          0  ...  121.834662   4.658832   8.634422   \n",
              "4            0          0          1  ... -170.518963  13.341847  36.440570   \n",
              "..         ...        ...        ...  ...         ...        ...        ...   \n",
              "596          1          1          1  ...  124.395699   5.861944  15.780894   \n",
              "597          0          1          1  ... -160.581224  29.354587   1.599090   \n",
              "598          1          0          1  ...  178.456659  15.358528  43.492596   \n",
              "599          1          0          1  ...  179.430905  22.110760  17.269822   \n",
              "600          0          1          1  ...   72.956926  36.522332  19.590992   \n",
              "\n",
              "        TurnK3    ALT_Ref1    ALT_Ref2    ALT_Ref3    Pwheel1    Pwheel2  \\\n",
              "0    22.206740  497.009601  537.967562  236.358939  20.737285  21.548637   \n",
              "1    31.119822  195.527223  790.138195  288.295313  29.198833  15.097425   \n",
              "2    28.427521  519.701619   89.117520  592.265014  17.260841 -26.779056   \n",
              "3    10.661547  587.324370  334.795811  820.148106  22.978466  -4.269740   \n",
              "4     7.769409   30.223196  987.527111  477.129879  19.703314  14.632122   \n",
              "..         ...         ...         ...         ...        ...        ...   \n",
              "596   5.088956  282.254177  766.216734  258.725139  17.198286  -7.031181   \n",
              "597  35.123387  800.578315  347.872033  463.557716 -18.944399 -12.456607   \n",
              "598  17.467946  244.007155  464.659339  332.364667  14.363487 -25.310533   \n",
              "599  43.897891  487.446337  775.391812   18.176364  -3.547910  20.172602   \n",
              "600   7.002328   75.571287  872.801194  215.634687  19.951726 -24.181359   \n",
              "\n",
              "       Pwheel3  \n",
              "0    28.651301  \n",
              "1   -15.770147  \n",
              "2   -21.814282  \n",
              "3    11.779975  \n",
              "4    18.244655  \n",
              "..         ...  \n",
              "596  17.223219  \n",
              "597  10.819100  \n",
              "598  25.517936  \n",
              "599 -13.130236  \n",
              "600   8.455290  \n",
              "\n",
              "[601 rows x 24 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39d0e130-aac8-4da9-b17e-b2b7aecad402\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>TrainDelta</th>\n",
              "      <th>TestDelta</th>\n",
              "      <th>AP_Eng1</th>\n",
              "      <th>AP_Eng2</th>\n",
              "      <th>AP_Eng3</th>\n",
              "      <th>HDG_Mode1</th>\n",
              "      <th>HDG_Mode2</th>\n",
              "      <th>HDG_Mode3</th>\n",
              "      <th>ALT_Mode1</th>\n",
              "      <th>...</th>\n",
              "      <th>HDG_Ref3</th>\n",
              "      <th>TurnK1</th>\n",
              "      <th>TurnK2</th>\n",
              "      <th>TurnK3</th>\n",
              "      <th>ALT_Ref1</th>\n",
              "      <th>ALT_Ref2</th>\n",
              "      <th>ALT_Ref3</th>\n",
              "      <th>Pwheel1</th>\n",
              "      <th>Pwheel2</th>\n",
              "      <th>Pwheel3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>-89.042279</td>\n",
              "      <td>32.909379</td>\n",
              "      <td>43.025749</td>\n",
              "      <td>22.206740</td>\n",
              "      <td>497.009601</td>\n",
              "      <td>537.967562</td>\n",
              "      <td>236.358939</td>\n",
              "      <td>20.737285</td>\n",
              "      <td>21.548637</td>\n",
              "      <td>28.651301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-93.109998</td>\n",
              "      <td>19.364039</td>\n",
              "      <td>38.210679</td>\n",
              "      <td>31.119822</td>\n",
              "      <td>195.527223</td>\n",
              "      <td>790.138195</td>\n",
              "      <td>288.295313</td>\n",
              "      <td>29.198833</td>\n",
              "      <td>15.097425</td>\n",
              "      <td>-15.770147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>-113.480226</td>\n",
              "      <td>2.899508</td>\n",
              "      <td>25.331430</td>\n",
              "      <td>28.427521</td>\n",
              "      <td>519.701619</td>\n",
              "      <td>89.117520</td>\n",
              "      <td>592.265014</td>\n",
              "      <td>17.260841</td>\n",
              "      <td>-26.779056</td>\n",
              "      <td>-21.814282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>121.834662</td>\n",
              "      <td>4.658832</td>\n",
              "      <td>8.634422</td>\n",
              "      <td>10.661547</td>\n",
              "      <td>587.324370</td>\n",
              "      <td>334.795811</td>\n",
              "      <td>820.148106</td>\n",
              "      <td>22.978466</td>\n",
              "      <td>-4.269740</td>\n",
              "      <td>11.779975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>-170.518963</td>\n",
              "      <td>13.341847</td>\n",
              "      <td>36.440570</td>\n",
              "      <td>7.769409</td>\n",
              "      <td>30.223196</td>\n",
              "      <td>987.527111</td>\n",
              "      <td>477.129879</td>\n",
              "      <td>19.703314</td>\n",
              "      <td>14.632122</td>\n",
              "      <td>18.244655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>596</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>124.395699</td>\n",
              "      <td>5.861944</td>\n",
              "      <td>15.780894</td>\n",
              "      <td>5.088956</td>\n",
              "      <td>282.254177</td>\n",
              "      <td>766.216734</td>\n",
              "      <td>258.725139</td>\n",
              "      <td>17.198286</td>\n",
              "      <td>-7.031181</td>\n",
              "      <td>17.223219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>597</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>-160.581224</td>\n",
              "      <td>29.354587</td>\n",
              "      <td>1.599090</td>\n",
              "      <td>35.123387</td>\n",
              "      <td>800.578315</td>\n",
              "      <td>347.872033</td>\n",
              "      <td>463.557716</td>\n",
              "      <td>-18.944399</td>\n",
              "      <td>-12.456607</td>\n",
              "      <td>10.819100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>598</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>178.456659</td>\n",
              "      <td>15.358528</td>\n",
              "      <td>43.492596</td>\n",
              "      <td>17.467946</td>\n",
              "      <td>244.007155</td>\n",
              "      <td>464.659339</td>\n",
              "      <td>332.364667</td>\n",
              "      <td>14.363487</td>\n",
              "      <td>-25.310533</td>\n",
              "      <td>25.517936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>599</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>179.430905</td>\n",
              "      <td>22.110760</td>\n",
              "      <td>17.269822</td>\n",
              "      <td>43.897891</td>\n",
              "      <td>487.446337</td>\n",
              "      <td>775.391812</td>\n",
              "      <td>18.176364</td>\n",
              "      <td>-3.547910</td>\n",
              "      <td>20.172602</td>\n",
              "      <td>-13.130236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>600</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>72.956926</td>\n",
              "      <td>36.522332</td>\n",
              "      <td>19.590992</td>\n",
              "      <td>7.002328</td>\n",
              "      <td>75.571287</td>\n",
              "      <td>872.801194</td>\n",
              "      <td>215.634687</td>\n",
              "      <td>19.951726</td>\n",
              "      <td>-24.181359</td>\n",
              "      <td>8.455290</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>601 rows × 24 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39d0e130-aac8-4da9-b17e-b2b7aecad402')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-39d0e130-aac8-4da9-b17e-b2b7aecad402 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-39d0e130-aac8-4da9-b17e-b2b7aecad402');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#code to extract some rules - Can also be done manually\n",
        "\n",
        "from sklearn.tree import _tree\n",
        "from sklearn import tree\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer\n",
        "import math\n",
        "\n",
        "def get_rules(tree, feature_names, class_names): #this function is taken from: https://mljar.com/blog/extract-rules-decision-tree/\n",
        "    tree_ = tree.tree_\n",
        "    feature_name = [\n",
        "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
        "        for i in tree_.feature\n",
        "    ]\n",
        "\n",
        "    paths = []\n",
        "    path = []\n",
        "    \n",
        "    def recurse(node, path, paths):\n",
        "        \n",
        "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
        "            name = feature_name[node]\n",
        "            threshold = tree_.threshold[node]\n",
        "            p1, p2 = list(path), list(path)\n",
        "            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
        "            recurse(tree_.children_left[node], p1, paths)\n",
        "            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
        "            recurse(tree_.children_right[node], p2, paths)\n",
        "        else:\n",
        "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
        "            paths += [path]\n",
        "            \n",
        "    recurse(0, path, paths)\n",
        "\n",
        "    # sort by samples count\n",
        "    samples_count = [p[-1][1] for p in paths]\n",
        "    ii = list(np.argsort(samples_count))\n",
        "    paths = [paths[i] for i in reversed(ii)]\n",
        "    \n",
        "    rules = []\n",
        "    for path in paths:\n",
        "        rule = \"if \"\n",
        "        \n",
        "        for p in path[:-1]:\n",
        "            if rule != \"if \":\n",
        "                rule += \" and \"\n",
        "            rule += str(p)\n",
        "        rule += \" then \"\n",
        "        if class_names is None:\n",
        "            rule += \"response: \"+str(np.round(path[-1][0][0][0],3))\n",
        "        else:\n",
        "            classes = path[-1][0][0]\n",
        "            l = np.argmax(classes)\n",
        "            rule += f\"class: {class_names[l]} (proba: {np.round(100.0*classes[l]/np.sum(classes),2)}%)\"\n",
        "        rule += f\" | based on {path[-1][1]:,} samples\"\n",
        "        rules += [rule]\n",
        "        \n",
        "    return rules\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"autopilot_R1_4_1_regression_3500_value_1.csv\")\n",
        "\n",
        "X_train = data.drop(\"Label\", axis = 1)\n",
        "X_train = X_train.drop(\"Fitness\", axis = 1)\n",
        "y_train = data.Label.values\n",
        "\n",
        "dtmodel = BayesSearchCV(tree.DecisionTreeClassifier(random_state = 0), {'min_samples_leaf': Integer(1, max(2, math.floor(len(y_train/2))))}, n_iter = 100, optimizer_kwargs = {'acq_func': 'EI'})\n",
        "\n",
        "dtmodel.fit(X_train[:300], y_train[:300])\n",
        "\n",
        "clf = dtmodel.best_estimator_\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "c = 0\n",
        "\n",
        "rules = get_rules(clf, X_train.columns, ['0','1'])\n",
        "for r in rules:    \n",
        "  if r.find('class: 0') != -1 and r.find('100.0') != -1:\n",
        "    print(r)\n",
        "    c = c + 1"
      ],
      "metadata": {
        "id": "49xZov-MC-6F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3461eae0-5124-442d-bd63-188d9080ce04"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n",
            "/usr/local/lib/python3.8/dist-packages/skopt/optimizer/optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "if (HDG_Mode1 > 0.5) and (TurnK1 > 2.82) and (TurnK2 > 2.061) and (ALT_Ref1 > 9.864) and (Pwheel1 > -28.363) then class: 0 (proba: 100.0%) | based on 231 samples\n",
            "if (HDG_Mode1 <= 0.5) and (AP_Eng1 <= 0.5) and (TurnK1 > 3.041) then class: 0 (proba: 100.0%) | based on 128 samples\n",
            "if (HDG_Mode1 <= 0.5) and (AP_Eng1 > 0.5) and (TurnK1 > 30.219) then class: 0 (proba: 100.0%) | based on 53 samples\n",
            "if (HDG_Mode1 > 0.5) and (TurnK1 <= 2.82) and (AP_Eng1 > 0.5) then class: 0 (proba: 100.0%) | based on 13 samples\n",
            "if (HDG_Mode1 > 0.5) and (TurnK1 > 2.82) and (TurnK2 <= 2.061) and (Pwheel3 > -10.455) then class: 0 (proba: 100.0%) | based on 9 samples\n",
            "if (HDG_Mode1 > 0.5) and (TurnK1 > 2.82) and (TurnK2 > 2.061) and (ALT_Ref1 > 9.864) and (Pwheel1 <= -28.363) and (Pwheel1 <= -28.426) then class: 0 (proba: 100.0%) | based on 7 samples\n",
            "if (HDG_Mode1 > 0.5) and (TurnK1 > 2.82) and (TurnK2 > 2.061) and (ALT_Ref1 <= 9.864) and (ALT_Ref1 <= 7.313) then class: 0 (proba: 100.0%) | based on 4 samples\n",
            "if (HDG_Mode1 > 0.5) and (TurnK1 > 2.82) and (TurnK2 <= 2.061) and (Pwheel3 <= -10.455) and (ALT_Ref2 <= 142.94) then class: 0 (proba: 100.0%) | based on 1 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fzniB-AAY1XC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4i_x8Dawpkrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wittgenstein"
      ],
      "metadata": {
        "id": "YcR8KNyVDmVy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eacf061-8a4a-4e4a-e872-a9d0c248c81c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wittgenstein\n",
            "  Downloading wittgenstein-0.3.2-py3-none-any.whl (124 kB)\n",
            "\u001b[K     |████████████████████████████████| 124 kB 11.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from wittgenstein) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from wittgenstein) (1.3.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->wittgenstein) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->wittgenstein) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->wittgenstein) (1.15.0)\n",
            "Installing collected packages: wittgenstein\n",
            "Successfully installed wittgenstein-0.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Rules\n",
        "\n",
        "import wittgenstein as lw\n",
        "import pandas as pd\n",
        "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Integer\n",
        "\n",
        "data = pd.read_csv(\"tustinr4_R4b_regression_3500_value_1.csv\")\n",
        "\n",
        "#y = data.Label.values\n",
        "#X = data.drop(\"Label\", axis = 1)\n",
        "#X = X.drop(\"Fitness\", axis = 1)\n",
        "\n",
        "testdata = pd.read_csv(\"tustinr4_R4b_regression_3500_value_2.csv\")\n",
        "\n",
        "\n",
        "\n",
        "X_train = data.drop(\"Label\", axis = 1)\n",
        "X_train = X_train.drop(\"Fitness\", axis = 1)\n",
        "y_train = data.Label.values\n",
        "\n",
        "X_test = testdata.drop(\"Label\", axis = 1)\n",
        "X_test = X_test.drop(\"Fitness\", axis = 1)\n",
        "y_test = testdata.Label.values\n",
        "\n",
        "\n",
        "drmodel = BayesSearchCV(lw.RIPPER(random_state = 0), {'prune_size': [0.1, 0.8], 'k': [1, 3]}, n_iter = 100, optimizer_kwargs = {'acq_func': 'EI'})\n",
        "\n",
        "drmodel.fit(X_train[:300], y_train[:300])\n",
        "\n",
        "clf = drmodel.best_estimator_\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "precisionpass = (tp) / (tp + fp)\n",
        "recallpass = (tp) / (tp + fn)\n",
        "\n",
        "precisionfail = (tn) / (tn + fn)\n",
        "recallfail = (tn) / (tn + fp)\n",
        "\n",
        "print(\"accuracy: \", accuracy)\n",
        "print(\"recall pass: \", recallpass)\n",
        "print(\"recall fail: \", recallfail)\n",
        "print(\"precision pass: \", precisionpass)\n",
        "\n",
        "print(\"precision fail: \", precisionfail)\n"
      ],
      "metadata": {
        "id": "nT9euanyDDN6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ffb29d-2950-438c-c9e1-b31c0a879b46"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91        52\n",
            "           1       0.95      0.83      0.89        48\n",
            "\n",
            "    accuracy                           0.90       100\n",
            "   macro avg       0.91      0.90      0.90       100\n",
            "weighted avg       0.91      0.90      0.90       100\n",
            "\n",
            "accuracy:  0.9\n",
            "recall pass:  0.8333333333333334\n",
            "recall fail:  0.9615384615384616\n",
            "precision pass:  0.9523809523809523\n",
            "precision fail:  0.8620689655172413\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wittgenstein as lw\n",
        "#extract rules for ensemble DR\n",
        "from operator import itemgetter\n",
        "import pandas as pd\n",
        "\n",
        "def GetConfSamp(dictt, indexx, feat):\n",
        "\n",
        "  data = pd.read_csv(\"tustinr4_R4b_regression_3500_value_1.csv\")\n",
        "  \n",
        "\n",
        "  trues = 0\n",
        "  inrange = 0\n",
        "\n",
        "  for i in range(len(data.index)):\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    #print(dictt)\n",
        "    for var in dictt:\n",
        "\n",
        "      if dictt[var][2] == \"between\":\n",
        "\n",
        "        if  dictt[var][0]<= data.loc[i, var]<= dictt[var][1]:\n",
        "          count = count + 1\n",
        "      \n",
        "      elif dictt[var][2] == \"greater\":\n",
        "\n",
        "        if  data.loc[i, var]>= dictt[var][0]:\n",
        "          count = count + 1\n",
        "\n",
        "      elif dictt[var][2] == \"smaller\":\n",
        "\n",
        "        if  data.loc[i, var]<= dictt[var][0]:\n",
        "          count = count + 1 \n",
        "\n",
        "      elif dictt[var][2] == \"equal\":\n",
        "        \n",
        "        if  data.loc[i, var]== dictt[var][0]:\n",
        "          count = count + 1 \n",
        "        \n",
        "    if count == len(dictt): #all the variables are in the ranges\n",
        "      inrange = inrange + 1\n",
        "      if data.loc[i, 'Label'] == 0: #class 0\n",
        "          trues = trues + 1\n",
        "    else:\n",
        "      continue\n",
        "  \n",
        "  #print(trues, inrange)\n",
        "  return (trues/inrange)*100, inrange\n",
        "\n",
        "\n",
        "def ExtractBounds(rule):\n",
        "  #print(type(rule))\n",
        "  #print(\"rule\", rule)\n",
        "  rule = rule[1:-1].split('^')\n",
        "  #print(\"rule\", rule)\n",
        "\n",
        "  dictt = {}\n",
        "\n",
        "  for i in range(len(rule)):\n",
        "    #print(rule[i])\n",
        "    if rule[i].find('>') != -1:\n",
        "\n",
        "      dictt[rule[i][:rule[i].find('=')]] = [float(rule[i][rule[i].find('=')+2 : len(rule[i])]), \"\", \"greater\"]\n",
        "\n",
        "    elif rule[i].find('<') != -1:\n",
        "\n",
        "      dictt[rule[i][:rule[i].find('=')]] = [float(rule[i][rule[i].find('<')+1 : len(rule[i])]), \"\", \"smaller\"]\n",
        "\n",
        "    elif rule[i].find('-') != -1:\n",
        "\n",
        "      for k in range(rule[i].find('=')+2, len(rule[i])):\n",
        "        if rule[i][k] == '-':\n",
        "          a = rule[i][rule[i].find('=')+1: k]\n",
        "          k = k\n",
        "          break\n",
        "      #print(a, \"****\", k+1, rule[i][k+1:len(rule[i])])\n",
        "      dictt[rule[i][:rule[i].find('=')]] = [float(a), float(rule[i][k+1:len(rule[i])]), \"between\"]\n",
        "\n",
        "    elif rule[i].find('=') != -1:\n",
        "\n",
        "      #print(rule[i][rule[i].find('=')+1 : len(rule[i])])\n",
        "      #print(len(rule[i][rule[i].find('=')+1 : len(rule[i])]))\n",
        "      dictt[rule[i][:rule[i].find('=')]] = [float(rule[i][rule[i].find('=')+1 : len(rule[i])]), \"\", \"equal\"]      \n",
        "\n",
        "  #print(\"dictt is\", dictt)\n",
        "  \n",
        "  return dictt\n",
        "\n",
        "\n",
        "\n",
        "rules= []\n",
        "\n",
        "\n",
        "for i in range(1, 2):\n",
        "\n",
        "  data = pd.read_csv(\"tustinr4_R4b_regression_3500_value_1.csv\") \n",
        "  \n",
        "\n",
        "  X_train = data.drop(\"Label\", axis = 1)\n",
        "  X_train = X_train.drop(\"Fitness\", axis = 1)\n",
        "  y_train = data.Label.values\n",
        "\n",
        "  drmodel = BayesSearchCV(lw.RIPPER(random_state = 0), {'prune_size': [0.1, 0.8], 'k': [1, 3]}, n_iter = 100, optimizer_kwargs = {'acq_func': 'EI'})\n",
        "\n",
        "  drmodel.fit(X_train[:300], y_train[:300])\n",
        "\n",
        "  clf = drmodel.best_estimator_\n",
        "\n",
        "  try:\n",
        "    clf.fit(X_train, y_train, pos_class=0) #to get the fail class rules\n",
        "  except:\n",
        "    print(\"No rules\")\n",
        "    print('*****************')\n",
        "    continue\n",
        "  #clf.out_model()\n",
        "  clf.ruleset_.out_pretty()\n",
        "\n",
        "  #print(clf.ruleset_.count_conds())\n",
        "  rules.append(clf.ruleset_)\n",
        "\n",
        "\n",
        "  print(\"******************\")\n",
        "\n",
        "\n",
        "#print(rules)\n",
        "\n",
        "newrules = []\n",
        "\n",
        "res = pd.DataFrame(columns= ['Run'+str(i) for i in range(1,21)])\n",
        "\n",
        "confs = [[] for i in range(20)]\n",
        "\n",
        "for i in range(len(rules)):\n",
        "  listt = []\n",
        "  for j in range(len(rules[i])):\n",
        "\n",
        "    listt.append(str(rules[i][j]))\n",
        "\n",
        "    c = str(rules[i][j])\n",
        "    dictt = ExtractBounds(c)\n",
        "\n",
        "    #print(a,b)\n",
        "  \n",
        "    conf, samples = GetConfSamp(dictt, i, X_train.columns)\n",
        "\n",
        "    confs[i].append((conf, samples))\n",
        "\n",
        "    print(conf, samples)\n",
        "\n",
        "  \n",
        "  print(\"*************\")\n",
        "  newrules.append(listt)\n",
        "\n",
        "res.loc[res.shape[0]] = [confs[k] for k in range(20)]\n",
        "res.to_excel('results.xlsx')\n",
        "\n"
      ],
      "metadata": {
        "id": "2rmVldTnDtQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fc68eb-127e-49ea-ef70-145e886d013b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[BL=0.11-2.14 ^ TL=3.64-5.75] V\n",
            "[BL=-1.84-0.11] V\n",
            "[BL=0.11-2.14 ^ TL=-4.2--2.69] V\n",
            "[BL=0.11-2.14 ^ TL=-6.09--4.2] V\n",
            "[BL=0.11-2.14] V\n",
            "[BL=5.99-8.0 ^ TL=-8.14--6.09] V\n",
            "[BL=-4.12--1.84 ^ TL=5.75-7.87] V\n",
            "[TL=<-8.14 ^ BL=>8.0] V\n",
            "[BL=5.99-8.0 ^ TL=-4.2--2.69] V\n",
            "[BL=<-8.06 ^ TL=5.75-7.87] V\n",
            "[TL=-6.09--4.2 ^ BL=3.86-5.99] V\n",
            "[TL=-0.49-1.44 ^ BL=-8.06--5.96] V\n",
            "[BL=>8.0 ^ TL=-6.09--4.2] V\n",
            "[TL=<-8.14 ^ BL=3.86-5.99] V\n",
            "[TL=-2.69--0.49 ^ BL=5.99-8.0] V\n",
            "[BL=-4.12--1.84 ^ TL=3.64-5.75] V\n",
            "[IC=>16.18 ^ BL=-8.06--5.96] V\n",
            "[TL=-2.69--0.49 ^ BL=2.14-3.86] V\n",
            "[TL=-2.69--0.49 ^ BL=>8.0] V\n",
            "[BL=2.14-3.86 ^ TL=-4.2--2.69] V\n",
            "[TL=<-8.14 ^ BL=2.14-3.86] V\n",
            "[BL=<-8.06 ^ TL=3.64-5.75] V\n",
            "[TL=>7.87 ^ BL=-4.12--1.84] V\n",
            "[BL=-5.96--4.12 ^ TL=1.44-3.64] V\n",
            "[TL=<-8.14 ^ BL=5.99-8.0] V\n",
            "[BL=-8.06--5.96 ^ TL=5.75-7.87] V\n",
            "[TL=-0.49-1.44 ^ BL=<-8.06] V\n",
            "[BL=-8.06--5.96 ^ TL=>7.87] V\n",
            "[TL=-8.14--6.09 ^ BL=2.14-3.86] V\n",
            "[BL=>8.0 ^ TL=-4.2--2.69] V\n",
            "[BL=3.86-5.99 ^ TL=-8.14--6.09] V\n",
            "[TL=-8.14--6.09 ^ BL=>8.0] V\n",
            "[TL=>7.87 ^ BL=-5.96--4.12] V\n",
            "[BL=3.86-5.99 ^ TL=-2.69--0.49] V\n",
            "[BL=-5.96--4.12 ^ TL=5.75-7.87] V\n",
            "[TL=3.64-5.75 ^ BL=-5.96--4.12] V\n",
            "[TL=>7.87 ^ BL=<-8.06] V\n",
            "[BL=-4.12--1.84 ^ IC=3.77-7.35] V\n",
            "[BL=-8.06--5.96 ^ TL=3.64-5.75]]\n",
            "******************\n",
            "100.0 9\n",
            "98.38709677419355 62\n",
            "100.0 10\n",
            "100.0 6\n",
            "91.93548387096774 62\n",
            "100.0 8\n",
            "100.0 8\n",
            "100.0 7\n",
            "100.0 6\n",
            "100.0 12\n",
            "100.0 7\n",
            "100.0 7\n",
            "100.0 9\n",
            "100.0 8\n",
            "100.0 9\n",
            "100.0 7\n",
            "100.0 6\n",
            "100.0 6\n",
            "100.0 6\n",
            "100.0 6\n",
            "100.0 6\n",
            "100.0 5\n",
            "100.0 6\n",
            "100.0 8\n",
            "100.0 5\n",
            "100.0 3\n",
            "80.0 5\n",
            "100.0 5\n",
            "100.0 7\n",
            "100.0 4\n",
            "100.0 6\n",
            "100.0 5\n",
            "100.0 6\n",
            "100.0 3\n",
            "100.0 2\n",
            "100.0 4\n",
            "100.0 3\n",
            "100.0 3\n",
            "100.0 6\n",
            "*************\n"
          ]
        }
      ]
    }
  ]
}